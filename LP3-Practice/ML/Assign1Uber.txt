Assingment 1st ML
Predict the price of the Uber ride from a given pickup point to the agreed drop-off location.
Perform following tasks:
1. Pre-process the dataset.
2. Identify outliers.
3. Check the correlation.
4. Implement linear regression and random forest regression models.
5. Evaluate the models and compare their respective scores like R2, RMSE, etc.


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
import datetime as dt

# Load the dataset
df = pd.read_csv('uber-fares-dataset.csv')

# Display the first few rows of the dataset
print(df.head())

# Convert pickup_datetime to datetime format
df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'], errors='coerce')

# Remove rows with missing values
df = df.dropna()

# Extract date, hour, day of the week, and other useful features from the pickup_datetime
df['pickup_date'] = df['pickup_datetime'].dt.date
df['pickup_hour'] = df['pickup_datetime'].dt.hour
df['pickup_day'] = df['pickup_datetime'].dt.dayofweek  # Monday=0, Sunday=6
df['pickup_month'] = df['pickup_datetime'].dt.month
df = df.drop(columns=['pickup_datetime', 'pickup_date'])  # Drop original date column

# Convert categorical features to numeric (e.g., convert 'fare_amount' to numeric if necessary)
df['fare_amount'] = pd.to_numeric(df['fare_amount'], errors='coerce')

# Remove rows where fare_amount or passenger_count have implausible values
df = df[(df['fare_amount'] > 0) & (df['passenger_count'] > 0)]

# Drop any remaining NaN values
df.dropna(inplace=True)


# Plot boxplots to check for outliers in fare_amount
plt.figure(figsize=(10, 6))
sns.boxplot(df['fare_amount'])
plt.title('Boxplot of Fare Amount')
plt.show()

# Remove outliers in fare_amount based on a threshold (e.g., values higher than 99th percentile)
upper_limit = df['fare_amount'].quantile(0.99)
df = df[df['fare_amount'] < upper_limit]


# Compute correlation matrix
corr_matrix = df.corr()

# Visualize correlation matrix
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Matrix')
plt.show()


# Define the target variable and features
X = df.drop(columns=['fare_amount'])
y = df['fare_amount']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features for Linear Regression
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Linear Regression
lr_model = LinearRegression()
lr_model.fit(X_train_scaled, y_train)
y_pred_lr = lr_model.predict(X_test_scaled)

# Random Forest Regression
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

from sklearn.metrics import mean_squared_error, r2_score

# Linear Regression Metrics
rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))
r2_lr = r2_score(y_test, y_pred_lr)
print("Linear Regression - RMSE:", rmse_lr)
print("Linear Regression - R2 Score:", r2_lr)

# Random Forest Regression Metrics
rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))
r2_rf = r2_score(y_test, y_pred_rf)
print("Random Forest - RMSE:", rmse_rf)
print("Random Forest - R2 Score:", r2_rf)